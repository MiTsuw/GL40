\chapter{Jeux de tests et évaluation}
\label{chapitre_jeux_de_tests}
L'évaluation des heuristiques nécessite l'utilisation d'instances de problème représenta\-ti\-ves de la difficulté et de la diversité des cas réels d'application. Pour évaluer les méthodes d'optimisation, sont proposés un ensemble de jeux de tests, appelés benchmarks. Chaque dossier de test comporte des instances, issues de cas réels ou générées automatiquement, sur lesquelles sont appliqués des schémas de résolution suivant la configuration des para\-mètres choisis.

Un fichier de configuration type \textit{config.cfg} du programme d'opti\-misation est fourni pour l'exécution des jeux de tests. Il définit une exécution standard avec l'ensemble des fonction\-nalités d'optimisation activées. Il peut être utilisé avec toute instance sans exception, mais peut être modifié ou ajusté suivant la fonction ou l'option que l'on veut utiliser. Les variations des paramètres de configuration pour les différents tests de validation
sont minimes par rapport a la configuration type. Nous décrivons les scénarios de tests proposés en indiquant dans chaque cas les fonctionnalités testées et les changements dans les paramètres de configuration de la configuration type.

Les tests de validation se décomposent en deux groupes, les tests avec génération d'instances automatique et les tests avec instances issues de cas réels ou instances spécifiques. Ils sont présentés ci-après avec des exemples de résultats. Noter qu'il est possible de lancer une exécution complète automatisée de tous les tests à l'aide de scripts systèmes d'exécution tels que la commande \textit{./test/test\_all.bat}.

Les dossiers de tests avec génération automatique d'instances sont les suivants :
\begin{itemize}
\item     \textit{test exemple type avec génération automatique}
\end{itemize} 

Les dossiers de tests portant sur des instances issues de cas réels sont les suivants :
\begin{itemize}
\item     \textit{test exemple type}
\end{itemize} 

\section{Critères d'évaluation}

Les valeurs des critères d'évaluation d'une solution sont renvoyées dans le fichier \textit{output.stats}. Ils correspondent presque exactement aux objectifs du problème. Nous distinguons les objectifs des critères dans la mesure ou les premiers renvoient à la repré\-sentation interne de l'évaluation de la solution et les seconds renvoient aux valeurs présentées à l'uti\-lisateur extérieur. Les cri\-tères correspondent aux objec\-tifs, excepté qu'il peuvent être plus nombreux et complémentaires.

Les critères d'évaluation d'une solution renvoyés dans le fichier \textit{output.stats} sont les suivants :

\begin{itemize}

\item \textit{iteration} : numéro d'itération lors de l'évaluation
\item \textit{f\_objectif\_1} : premier objectif
\item \textit{f\_objectif\_2} : second objectif
\item \textit{f\_objectif\_3} : troisième objectif
\item \textit{duree}(s) : durée d'exécution en secondes
\item \textit{duree}(s.xx) : durée d'exécution en secondes et millisecondes

\end{itemize} 

Noter que chaque répertoire de test comporte un fichier Excel pour l'analyse statistique des résultats de nom \textit{result\_analysis.xlsx}. Il est ainsi possible d'évaluer rapidement les performances moyennes de l'algorithme relativement à un grand nombre d'exécutions.

\section{Test standard avec génération automatique}

Il s'agit de tester des fonctionnalités sur des jeux de tests générés automatiquement à partir d'un modèle. Le test permet aussi d'illustrer la post-optimisation. Pour dissocier des fonctions, on utilise dans ce test un mode "post-optimisation" qui applique une nouvelle fonction, ou configuration, sur la solution précédemment obtenue. Pour configurer l'application en mode post-optimisation, il suffit de spécifier les paramètres suivants :
\begin{itemize}
\item  $constructFromScratchParam = false$
\item  $MAnbOfInternalConstructs = 0$ 
\end{itemize} 

Le principe du test consiste à lancer une première phase d'optimisation avec des paramètres actifs et ensuite à lancer une post-optimisation en retirant l'option en question. L'ajout ou suppression des fonctions peut également être réalisé via les poids des objectifs. Les paramètres de confi\-guration de départ sont les suivants :

\begin{itemize}
\item $utiliseFonction = true$
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{./Img/test.jpg}
\caption{Solution type.}
\label{figure:reptr}
\end{figure}

Un exemple de résultat est visualisé à la figure \ref{figure:reptr}. On constate que les contraintes sont satisfaites. La solution est admissible sur l'ensemble des critères.

\section{Test standard cas réel}

Il s'agit d'un test issu de cas réels considéré difficile à résoudre. Il est résolu en moins de 0.1 secondes sur un PC Dual Core avec GPU. Dans ce cas difficile, pour accélérer au maximum la vitesse de résolution, il convient d'inhiber l'activation de certaines fonctions. Ces fonctions peuvent être inhibées avec les commandes :
\begin{itemize}
\item $utiliseFontion\_1 = false$
\item $utiliseFonction\_2 = false$
\end{itemize} 

Une solution est représentée à la figure \ref{figure:test}.

\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{./Img/test.png}
\caption{Solution type.}
\label{figure:test}
\end{figure}

